<!doctype html>
<html lang="en">
<head>
<meta charset="UTF-8">
    <title>Is your AI Racist?</title>

<!--Remy Sharp Shim --> 
<!--[if lte IE 9]> 
<script src="https://oss.maxcdn.com/html5shiv/3.7.2/html5shiv.min.js" type="text/javascript" >
</script> 
<![endif]-->

    
    <link rel="stylesheet" type="text/css" href="css/styles.css">
    <link href="https://fonts.googleapis.com/css?family=Playfair+Display" rel="stylesheet">
    
  
</head>
    
<body>
   <div id="wrapper">  
   <header>
       <h1>Is Your AI Racist?</h1>
   </header>
           
   <nav>
      <ul>
         <li><a href="index.html">HOME</a></li>
         <li><a href="">Unintentional AI</a>
         <li><a href="">Intentional AI</a></li>
              
      </ul>
                 
   </nav>
   <div id="banner">
      <h2>Bias in Artificial Intelligence</h2>
   </div><!-- end banner-->

   <main>
      <h2>
        What is Artificial Intelligence?
      </h2>
       <br>
           <p>Artificial Intelligence (AI) ) is the ability of computer program or a machine to think and learn. It is also a field of study which tries to make computers "smart". They work on their own without being encoded with commands.</p>
       <br>
       
       <h2>What is Algorithmic Bias?</h2>
       <br>
       <p>Wikipedia defines Algorithmic Bias as (occuring) when a computer system reflects the implicit values of the humans who are involved in coding, collecting, selecting, or using data to train the algorithm.</p>
       <br>
       
       <h2>How Does an AI become Biased?</h2>
       <p>Bias can enter into Artificial Intelligence as a result of pre-existing cultural, social, or institutional expectations; because of technical limitations of their design; or by being used in unanticipated contexts or by audiences who are not considered in the software's initial design.
</p>
       <br>
       
       <h2>Is this Deliberate?</h2>
       <p>. “Machine-learning algorithms haven’t been optimized for any definition of fairness,” says Deirdre Mulligan, associate professor, UC Berkeley School of Information. “They have been optimized to do a task... It’s not that the programmer sits down and does this on purpose, it’s something that he or she just doesn’t know and that way, the algorithms of these outcomes become flawed.”
           <br>
            Essentially,If the data that the machine is fed contains unconscious bias, then the outcome of the machine learning will also contain that bias.
</p>
       <br>
        <h2>Examples of Unitentional Bias</h2>
       <br>
       <p>Our first example kicks off with a few simple google searches. Here is a search result for the word “engineer.” What do you see? </p>
       
       <br>
       
       <img src="images/engineer.jpg" class="desktop" alt="" />
       
       <br>
       
       <p>Here is another example: an image search of the word “assistant.”  As you can see the majority of the pictures are all of women, or women assisting men. 
</p>
       <br>
       
       <img src="images/assistant.jpg" class="desktop" alt="" />
       
      <br>
       
       <p>This gender bias extends beyond just image searches, a recent paper shows that some concerning biases seen in human psychology experiments are also readily acquired by algorithms. The words “female” and “woman” were more closely associated with arts and humanities occupations and with the home, while “male” and “man” were closer to maths and engineering professions.</p>
       
       <br>
       
       <h2>Examples of Intentional Bias</h2>
       <br>
       <p>An example of intentional bias being caused by users is the 2016 twitter AI named Tay. Tay, also known as TayTweets, was created by microsoft to try and see if an AI can make tweets similar to a teenager as an experiment in “conversational understanding.” “Unfortunately, the conversations didn't stay playful for long. Pretty soon after Tay launched, people starting tweeting the bot with all sorts of misogynistic, racist, and Donald Trumpist remarks. And Tay — being essentially a robot parrot with an internet connection — started repeating these sentiments back to users, proving correct that old programming adage: flaming garbage pile in, flaming garbage pile out.”</p>
       <br>
       
       <p>Image placeholder</p>
       
       <br>
       
       <p>Now, while these screenshots make it seem like Tay has become a product of the internet’s worst tendencies, it’s not as straightforward as that. Once the bot’s tweets were looked through, it was noticeable that the worst tweets were the result of copying users. One function of the AI was that if you told Tay to “repeat after me” it would tweet it soon after.</p>
       <br>
       
       <h2>How are Developers Working to Overcome Bias?</h2>
       <p>Overcoming the bias of the consumer has proven to be a bit more tricky. User input affects machine learning dramatically. Developers are trying to creatively come up with solutions to account for and limit biased user data without overstepping the whole purpose, which is allowing the user to supply their own input. One of the ways this is being done is by compensating for cultural bias when writing code for AI. Artificially created systems reflect our society’s values. If you have an imperfect society providing data for machine learning, then it’s no surprise the results will ultimately reflect that culture’s forms of bias. Making sure AI systems are well trained on balanced data prior to being released helps combat the machine learning of cultural bias. Another option being considered and implemented is the policing and monitoring of AI software after it has been released. Observing AI in action and stepping in to take corrective measures when AI becomes too deviant from its intended purpose may help safeguard the integrity of the software. </p>
       <br>
       <p>In some ways, ultimately it is up to society to determine where the future of AI standards lie. Companies follow the profits, and with it the expectations of the consumer.</p> 
<br>
<p>Report issues, help test software, become a society that expects developers to audit AI software, engage!
</p>
   </main>
       
          
          
           
   <footer>
      <ul>
         <li>Copyright 2019 &copy;</li>
         <li> All Rights Reserved </li>
      </ul>
   </footer>
        
        </div> 
    </body>
    
    
</html>